# 机器学习的几种常见的评估方法

通常，我们可通过实验测试来对学习器的泛化误差进行评估并进而做出选择。为此，需要使用一个“测试集（testing set）”来测试学习器对新样本的判别能力，然后以测试集上的“测试误差（testing error）”作为泛化误差的近似。通常我们假设测试样本也是从样本真是分布中独立同分布采样而得。但需要注意的是，测试集应该尽可能与训练集互斥，即训练样本尽量不在训练集中出现、未在训练过程中使用过。

测试样本为什么要尽可能不出现在训练集中呢？为理解这一点，不妨考虑这样一个场景：老师除了 10 道习题供同学们练习，考试时老师又用同样的这 10 道题作为试题，这个考试成绩能否有效反映出同学们学的好不好呢？答案是否定的，可能有的同学只会做这 10 道题却能得高分，回到我们的问题上来，我们希望得到泛化性能强的模型，好比是希望同学们对课程学得好、获得了对所学知识的举一反三的能力；训练样本相当于给同学们练习的习题，测试过程则相当于考试，显然，若测试样本被用作训练了，则得到的将是过于“乐观”的估计结果。

可是，我们只有一个包含 m 个样例的数据集 D={(x1,y1),(x2,y2), ..., (xm,ym)}，既要训练，又要测试，怎样才能做到呢？答案是：通过对 D 进行适当的处理，从中产生训练集 S 和测试集 T 。

## 留出法
“留出法（hold-out）”直接将数据集 D 划分为两个互斥的集合，